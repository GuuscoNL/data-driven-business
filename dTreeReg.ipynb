{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "In dit notebook zal een Decision Tree Regressor model gebruikt worden om de duur van een storing te voorspellen. Dit wordt gedaan met feature variabelen die gevonden en geprepareerd zijn in \"DataPrep.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importeren gebruikte libraries\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from baseline import calculate_baseline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import plot_tree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/model_df.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# inladen data (al geprepareerd in ander bestand)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/model_df.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m model_df\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    193\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    194\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    196\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/model_df.pkl'"
     ]
    }
   ],
   "source": [
    "# inladen data (al geprepareerd in ander bestand)\n",
    "model_df = pd.read_pickle('data/model_df.pkl')\n",
    "model_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Er wordt een Decision Tree Regressor getraint met de features eerder geprepareerd. Eerst wordt er een test-train split gemaakt om het model mee te trainen en mee te testen. Daarna worden er modellen getraint met verschillende max_depths. Dit wordt geplot en in deze plots is te zien wat een goede depth is voor het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m model_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manm_tot_fh\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m model_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manm_tot_fh\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_df' is not defined"
     ]
    }
   ],
   "source": [
    "X = model_df.drop('anm_tot_fh', axis=1)\n",
    "y = model_df['anm_tot_fh']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 16) \n",
    "\n",
    "train_rmse, test_rmse = [], []\n",
    "train_r2, test_r2 = [], []\n",
    "\n",
    "\n",
    "# Train DTR model met verschillende max_depths\n",
    "for depth in tqdm(depths):\n",
    "    regressor = DecisionTreeRegressor(max_depth=depth, min_samples_leaf=0.05, criterion='squared_error', random_state=42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # Voorspellingen op de train set\n",
    "    train_predictions = regressor.predict(X_train)\n",
    "    train_rmse.append(sqrt(mean_squared_error(y_train, train_predictions)))\n",
    "    train_r2.append(r2_score(y_train, train_predictions))\n",
    "\n",
    "    # Voorspellingen op de test set\n",
    "    test_predictions = regressor.predict(X_test)\n",
    "    test_rmse.append(sqrt(mean_squared_error(y_test, test_predictions)))\n",
    "    test_r2.append(r2_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder wordt gekeken wat voor soort diepte goed is voor dit model. De RMSE en r2 scores worden vergeleken voor de train en de test set. Zoals te zien is er niet super veel verschil tussen de train en test set, wat betekend dat het model niet overfit is. Er is te zien dat de grafiek afvlakt bij diepte 5. Daarom wordt er gekozen voor max_depth = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot RMSE\n",
    "ax1.plot(depths, train_rmse, marker='o', linestyle='-', color='b', label='Train RMSE')\n",
    "ax1.plot(depths, test_rmse, marker='o', linestyle='-', color='r', label='Test RMSE')\n",
    "ax1.set_title('Depth vs. RMSE voor Decision Tree Regressor')\n",
    "ax1.set_xlabel('Max Depth')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_xticks(depths)\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot R2 score\n",
    "ax2.plot(depths, train_r2, marker='o', linestyle='-', color='b', label='Train R2')\n",
    "ax2.plot(depths, test_r2, marker='o', linestyle='-', color='r', label='Test R2')\n",
    "ax2.set_title('Depth vs. R2 voor Decision Tree Regressor')\n",
    "ax2.set_xlabel('Max Depth')\n",
    "ax2.set_ylabel('R2')\n",
    "ax2.set_xticks(depths)\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitieve Model\n",
    "\n",
    "Hieronder wordt er een model getraint met de gekozen max_depth. Het model wordt gepickled en opgeslagen zodat deze gerbuikt kan worden in de GUI. Daarna worden de scores van het model vergeleken met de baseline scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "regressor = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=0.05, criterion='squared_error', random_state=42)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# pickle de regressor voor gebruik in de GUI\n",
    "with open('models/DecisionTreeRegressor.pkl', 'wb') as file:\n",
    "    pickle.dump(regressor, file)\n",
    "\n",
    "print(\"Root Mean Squared Error: \", rmse)\n",
    "print(\"R-squared (R2) Score: \", r2)\n",
    "\n",
    "baseline_rmse, baseline_r2 = calculate_baseline(model_df)\n",
    "print('Baseline RMSE: ', baseline_rmse)\n",
    "print('Baseline R2: ', baseline_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het model is met een minimaal verschil beter dan de baseline (de RMSE is een beetje lager en de R2 score is een heel klein beetje hoger)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Probability\n",
    "\n",
    "In dit hoofdstuk wordt er verder gekeken naar het gevonden model.\n",
    "\n",
    "Eerst worden de RMSE scores van elke leaf berekend. Als sommige scores een stuk lager zijn dan andere weten we dat er bepaalde voorspellingen heel goed zijn en andere een stuk minder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krijg de leaf nodes\n",
    "leaf_nodes = [i for i in range(regressor.tree_.node_count) if regressor.tree_.children_left[i] == regressor.tree_.children_right[i]]\n",
    "\n",
    "rmse_per_leaf = {}\n",
    "\n",
    "# Loop over alle leaf nodes en bereken de RMSE\n",
    "for idx in leaf_nodes:\n",
    "    samples_in_node = regressor.tree_.n_node_samples[idx]\n",
    "    if samples_in_node > 0:\n",
    "        node_rmse = sqrt(regressor.tree_.impurity[idx] * samples_in_node / (samples_in_node + 1)) \n",
    "        rmse_per_leaf[idx] = node_rmse\n",
    "        print(\"Leaf Node {} has RMSE {}\".format(idx, node_rmse))\n",
    "        \n",
    "# Krijg de voorspelling per leaf node\n",
    "pred_per_leaf = {idx: regressor.tree_.value[idx][0][0] for idx, _ in rmse_per_leaf.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder wordt de decision tree geplot. Met behulp van dit figuur kunnen we zien op basis van welke features het model splits heeft gemaakt en welke dus belangrijk zijn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12)) \n",
    "plot_tree(regressor, filled=True, proportion=True, impurity=True, precision=2, feature_names=list(X.columns), node_ids=True)\n",
    "plt.title(\"Decision Tree Regressor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieronder wordt een grafiek gemaakt om historische data van 1 specifieke leaf uit de decision tree te laten zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_indices = regressor.apply(X)\n",
    "\n",
    "samples_in_leaves = {}\n",
    "\n",
    "# Iterate over unique leaf indices\n",
    "unique_leaf_indices = np.unique(leaf_indices)\n",
    "for leaf_index in unique_leaf_indices:\n",
    "    # Select the target values (y) that belong to the current leaf\n",
    "    samples_in_leaves[leaf_index] = y[leaf_indices == leaf_index].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf = 3\n",
    "durations = np.array(samples_in_leaves[leaf])\n",
    "mean_prediction = pred_per_leaf[leaf]\n",
    "\n",
    "percentile_95 = np.percentile(durations, 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de plot hieronder wordt een histogram gemaakt van de historische storingsduur data uit een specifieke leaf. De voorspelling die gemaakt wordt vanuit die leaf is ook te zien. Het blauwe gedeelte geeft aan hoeveel procent van de data onder de voorspelling ligt en het oranje hoeveel erboven. De groene lijn is de 95% lijn. Dit betekend dat 95% van de voorspellingen tussen de 5 min en deze waarde liggen. Deze informatie zal weergegeven worden in de dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "_, bins, _ = ax.hist(durations, bins=30, density=False, alpha=0.6, color='b', label='Historische storingsduur Data')\n",
    "ax.axvline(mean_prediction, color='r', linestyle='--', label=f'Mean Prediction = {mean_prediction:.0f}')\n",
    "ax.axvline(percentile_95, color='g', linestyle='--', label='95% Mark', linewidth=2)\n",
    "ax.set_xlabel('Duur storing (minuten)')\n",
    "ax.set_ylabel('Frequentie')\n",
    "ax.set_title('Storingsduur histogram')\n",
    "\n",
    "values_below_mean_prediction = durations[durations < mean_prediction]\n",
    "values_above_mean_prediction = durations[durations >= mean_prediction]\n",
    "percentage_below_mean = len(values_below_mean_prediction) / len(durations) * 100\n",
    "percentage_above_mean = len(values_above_mean_prediction) / len(durations) * 100\n",
    "\n",
    "right_side_color = 'orange'\n",
    "n, bins, patches = ax.hist(values_above_mean_prediction, bins=bins, alpha=0.6, color=right_side_color, label=f'Values Above Mean Prediction: {percentage_above_mean:.2f}%')\n",
    "\n",
    "labels = [\n",
    "    f'Waardes onder voorspelling: {percentage_below_mean:.2f}%', \n",
    "    f'Voorspelling: {mean_prediction:.2f} min',\n",
    "    f'95% van de data: {percentile_95:.2f} min', \n",
    "    f'Waardes boven voorspelling: {percentage_above_mean:.2f}%'\n",
    "    ]\n",
    "ax.legend(labels=labels)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
