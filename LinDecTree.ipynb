{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Decision Tree\n",
    "\n",
    "In dit notebook wordt een Linear Decision Tree model getraind op de geprepareerde dataset. Dit is een model die eerst een decision tree aanmaakt en bij de leaves gebruikt het model een lineare regressie model om de target waardes te voorspellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importeer gebruikte libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lineartree import LinearTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from baseline import calculate_baseline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_pickle('data/model_df.pkl')\n",
    "model_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er wordt een test-train split gemaakt voor het trainen en testen van het model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.drop('anm_tot_fh', axis=1)\n",
    "y = model_df['anm_tot_fh']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bereken de RMSE en R2 score van modellen met verschillende max_depths om te kijken welke optimaal is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 11) \n",
    "\n",
    "rmse = []\n",
    "r2 = []\n",
    "# Train LTR model met verschillende max_depths\n",
    "for depth in tqdm(depths):\n",
    "    regressor = LinearTreeRegressor(base_estimator=LinearRegression(), \n",
    "                                    linear_features=[0, 1],\n",
    "                                    split_features=[2, 3, 4, 5, 6],\n",
    "                                    max_depth=depth, \n",
    "                                    n_jobs=-1)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predictions = regressor.predict(X_test)\n",
    "    rmse.append(sqrt(mean_squared_error(y_test, predictions)))\n",
    "    r2.append(r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two plots side by side, first one showing RMSE and second one showing R2 score\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.plot(depths, rmse, marker='o', linestyle='-', color='b')\n",
    "ax1.set_title('Depth vs. RMSE for Linear Decision Tree')\n",
    "ax1.set_xlabel('Max Depth')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_xticks(depths)\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(depths, r2, marker='o', linestyle='-', color='b')\n",
    "ax2.set_title('Depth vs. R2 for Linear Decision Tree')\n",
    "ax2.set_xlabel('Max Depth')\n",
    "ax2.set_ylabel('R2')\n",
    "ax2.set_xticks(depths)\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een max_depth van 2 blijkt optimaal voor dit model (te zien in plots hierboven)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 2\n",
    "regressor = LinearTreeRegressor(base_estimator=LinearRegression(), \n",
    "                                linear_features=[0, 1],\n",
    "                                split_features=[2, 3, 4, 5, 6],\n",
    "                                max_depth=max_depth, \n",
    "                                n_jobs=-1)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"Root Mean Squared Error: \", rmse)\n",
    "print(\"R-squared (R2) Score: \", r2)\n",
    "\n",
    "baseline_rmse, baseline_r2 = calculate_baseline(model_df)\n",
    "print('Baseline RMSE: ', baseline_rmse)\n",
    "print('Baseline R2: ', baseline_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie\n",
    "\n",
    "Het model is met een minimaal verschil beter dan de baseline (de RMSE is een heel klein beetje lager en de R2 score is een heel klein beetje hoger)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
