{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit notebook zullen wij de features die wij in Data Exploration hebben gekozen, opschonen en zodanig aanpassen dat het door de modellen die wij interessant vinden, gebruikt kan worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run \"main.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import TargetEncoder\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst halen we rijen met een meldnummer dat al eerder is voorgekomen uit de dataset. \n",
    "Uit onze bevindingen\n",
    "\n",
    "Dit haalt zo'n 195000 entries weg en houden we er 350.000 over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missende waardes\n",
    "De features die wij hebben gekozen, missen soms waardes in de kolommen.\n",
    "Verschillende modellen kunnen hier niet mee omgaan. Om ervoor te zorgen dat deze onze modellen op de dataset kunnen werken, doen wij twee dingen. \\\n",
    "Wij verwijderen de rij(en) als missende waardes in deze kolom niet vaak voorkomen, en er geen goede waarde is om in te vullen. \\\n",
    "Ander proberen wij een waarde in te vullen. Dit kan een defaultwaarde zijn, die al in de dataset voorkomt, of wij kunnen zelf een nieuwe waarde hiervoor verzinnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn 1 rij die een prioriteit mist, deze rij halen we uit de database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA's verwijderen omdat het er weinig zijn\n",
    "df = df.dropna(subset=['stm_prioriteit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn 5 rijen die een geocode missen. Ook deze halen wij uit de database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stm_geo_mld\n",
    "# Some computers differ in how they interpret a column without values\n",
    "# So we remove both NaN values and empty strings\n",
    "df = df[df.stm_geo_mld != '']\n",
    "df = df.dropna(subset=['stm_geo_mld'])\n",
    "df['stm_geo_mld'] = df['stm_geo_mld'].astype(float).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor missende oorzaakcodes, vullen wij de code 999 in. \n",
    "Deze wordt in de database al gebruikt, en is niet beschreven in de data dictionary die wij hebben gekregen.\n",
    "Het is een default/missende waarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stm_oorz_code\n",
    "df['stm_oorz_code'] = df['stm_oorz_code'].fillna(221).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor missende techniekveld labels, vullen wij \"X\" in. Dit is de overige categorie, die al in de dataset terugkomt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stm_techn_mld\n",
    "df['stm_techn_mld'] = df['stm_techn_mld'].replace('', 'X')\n",
    "df['stm_techn_mld'] = df['stm_techn_mld'].fillna('X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor het contractgebied vervangen wij missende waardes met 999. Deze komt in de dataset niet voor en is vergeleken met de andere waardes in deze kolom, overduidelijk een default/overig value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stm_contractgeb_mld\n",
    "df['stm_contractgeb_mld'] = df['stm_contractgeb_mld'].fillna(999)\n",
    "df['stm_contractgeb_mld'] = df['stm_contractgeb_mld'].astype(float).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de oorzaakgroep vullen wij voor missende waardes \"ONBK\" in. Dit staat voor onbekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stm_oorz_groep\n",
    "df['stm_oorz_groep'] = df['stm_oorz_groep'].replace('', 'ONBK', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later gebruiken wij target-encoding, en hiervoor moeten wij een train/test split maken. \\\n",
    "Anders zouden de waardes, waarop wij het model testen, deels het model al hebben beïnvloed, en dat schaadt de testvaliditeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voor random state 33 zijn alle unieke waardes waarvoor wij target encoding gebruiken gerepresenteerd.\n",
    "# df_train is 80% van de dataset\n",
    "df_train = df.sample(frac = 0.8, random_state=33, weights=df['anm_tot_fh'])\n",
    "# df_test is de overige 20%\n",
    "df_test = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy encoding is een makkelijke en simpele manier om features met een lage kardinaliteit te encoderen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stm_prioriteit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze variabele gebruiken wij als een ordinale meetwaarde en hoeft dus niet veranderd te worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In het geval dummies gewenst zijn, kan je de volgende twee regels, en enkele regels verderop in de code uncommenten\n",
    "# prioriteit_dummies_train = pd.get_dummies(df_train['stm_prioriteit'], prefix='prio')\n",
    "# prioriteit_dummies_test = pd.get_dummies(df_test['stm_prioriteit'], prefix='prio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stm_techn_mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "techn_veld_dummies_train = pd.get_dummies(df_train['stm_techn_mld'], prefix='techn_veld')\n",
    "techn_veld_dummies_test = pd.get_dummies(df_test['stm_techn_mld'], prefix='techn_veld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stm_oorz_groep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oorz_groep_dummies_train = pd.get_dummies(df_train['stm_oorz_groep'], prefix='oorzgr')\n",
    "oorz_groep_dummies_test = pd.get_dummies(df_test['stm_oorz_groep'], prefix='oorzgr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target encoding geeft de nominale features een score op basis van het effect\n",
    "wat zij hebben op de target variabele.\n",
    "Het zet een nominale waarde in zekere mate om tot een continue waarde.\n",
    "Dit zorgt ervoor dat bepaalde modellen de feature kunnen gebruiken die dit anders niet konden,\n",
    "en geeft bepaalde modellen, zoals de decisionTree, een manier om de dataset op een grootschaligere manier\n",
    "te splitsen. Dus in plaats van dat het splitst op, de waarde is gelijk aan 1 van de 200 nominale waardes,\n",
    "splitst het op een waarde die representeert welk effect de waarde heeft op de target variabele.\n",
    "Waardes die over het algemeen in een lagere target variabele waarde resulteren, splitsen van de rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TargetEncoder\n",
    "# Onze target is een duur in minuten, dus continue\n",
    "tEnc = TargetEncoder(target_type=\"continuous\", random_state=42)\n",
    "y = df_train['anm_tot_fh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stm_oorz_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit het model op een feature in de traindata en maak een kolom aan met de geëncodeerde waardes\n",
    "X = np.array(df_train['stm_oorz_code']).reshape(-1, 1)\n",
    "tEnc.fit(X,y)\n",
    "df_train['oorz_code_enc'] = tEnc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Een dictionary met de encodings (voor het dashboard)\n",
    "oorzc_dict = {}\n",
    "for i in range(len(tEnc.categories_[0])):\n",
    "    cat, enc = tEnc.categories_[0][i], tEnc.encodings_[0][i]\n",
    "    oorzc_dict[cat] = enc\n",
    "# oorzc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In de testdata dezelfde kolom aanmaken met de encodings van de traindata\n",
    "df_test['oorz_code_enc'] = df_test['stm_oorz_code'].apply(lambda x : oorzc_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stm_geo_mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit het model op een feature in de traindata en maak een kolom aan met de geëncodeerde waardes\n",
    "X = np.array(df_train['stm_geo_mld']).reshape(-1, 1)\n",
    "tEnc.fit(X,y)\n",
    "df_train['geo_code_enc'] = tEnc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Een dictionary met de encodings (voor het dashboard)\n",
    "geo_dict = {}\n",
    "for i in range(len(tEnc.categories_[0])):\n",
    "    cat, enc = tEnc.categories_[0][i], tEnc.encodings_[0][i]\n",
    "    geo_dict[cat] = enc\n",
    "# geo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In de testdata dezelfde kolom aanmaken met de encodings van de traindata\n",
    "df_test['geo_code_enc'] = df_test['stm_geo_mld'].apply(lambda x : geo_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stm_contractgeb_mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit het model op een feature in de traindata en maak een kolom aan met de geëncodeerde waardes\n",
    "X = np.array(df_train['stm_contractgeb_mld']).reshape(-1, 1)\n",
    "tEnc.fit(X,y)\n",
    "df_train['contractgb_enc'] = tEnc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Een dictionary met de encodings (voor het dashboard)\n",
    "contrgb_dict = {}\n",
    "for i in range(len(tEnc.categories_[0])):\n",
    "    cat, enc = tEnc.categories_[0][i], tEnc.encodings_[0][i]\n",
    "    contrgb_dict[cat] = enc\n",
    "# contrgb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In de testdata dezelfde kolom aanmaken met de encodings van de traindata\n",
    "df_test['contractgb_enc'] = df_test['stm_contractgeb_mld'].apply(lambda x : contrgb_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stm_techn_mld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit het model op een feature in de traindata en maak een kolom aan met de geëncodeerde waardes\n",
    "X = np.array(df_train['stm_techn_mld']).reshape(-1, 1)\n",
    "tEnc.fit(X,y)\n",
    "df_train['techn_enc'] = tEnc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Een dictionary met de encodings (voor het dashboard)\n",
    "techn_dict = {}\n",
    "for i in range(len(tEnc.categories_[0])):\n",
    "    cat, enc = tEnc.categories_[0][i], tEnc.encodings_[0][i]\n",
    "    techn_dict[cat] = enc\n",
    "# techn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In de testdata dezelfde kolom aanmaken met de encodings van de traindata\n",
    "df_test['techn_enc'] = df_test['stm_techn_mld'].apply(lambda x : techn_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geprepareerde data exporteren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wij exporteren de dataframes naar csv bestanden, zodat de modellen in andere notebooks het makkelijk, snel en geprepareerd in kunnen laden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataframa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "# prioriteit_dummies_train = prioriteit_dummies.reset_index(drop=True)\n",
    "prioriteit = df_train['stm_prioriteit'].reset_index(drop=True)\n",
    "oorz_code_enc = df_train['oorz_code_enc'].reset_index(drop=True)\n",
    "geo_code_enc = df_train['geo_code_enc'].reset_index(drop=True)\n",
    "contractgb_enc = df_train['contractgb_enc'].reset_index(drop=True)\n",
    "techn_enc = df_train['techn_enc'].reset_index(drop=True)\n",
    "techn_veld_dummies = techn_veld_dummies_train.reset_index(drop=True)\n",
    "oorz_groep_dummies = oorz_groep_dummies_train.reset_index(drop=True)\n",
    "# fh_prog = df['stm_progfh_in_duur']\n",
    "\n",
    "features_to_use = [\n",
    "    # prioriteit_dummies\n",
    "    prioriteit,\n",
    "    oorz_code_enc,\n",
    "    geo_code_enc,\n",
    "    contractgb_enc,\n",
    "    techn_enc,\n",
    "    techn_veld_dummies,\n",
    "    oorz_groep_dummies\n",
    "]\n",
    "\n",
    "train_df = pd.concat([df_train['anm_tot_fh'], *features_to_use], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"data/train_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.reset_index(drop=True)\n",
    "# prioriteit_dummies_test = prioriteit_dummies.reset_index(drop=True)\n",
    "prioriteit = df_test['stm_prioriteit'].reset_index(drop=True)\n",
    "oorz_code_enc = df_test['oorz_code_enc'].reset_index(drop=True)\n",
    "geo_code_enc = df_test['geo_code_enc'].reset_index(drop=True)\n",
    "contractgb_enc = df_test['contractgb_enc'].reset_index(drop=True)\n",
    "techn_enc = df_test['techn_enc'].reset_index(drop=True)\n",
    "techn_veld_dummies = techn_veld_dummies_test.reset_index(drop=True)\n",
    "oorz_groep_dummies = oorz_groep_dummies_test.reset_index(drop=True)\n",
    "# fh_prog = df['stm_progfh_in_duur']\n",
    "\n",
    "features_to_use = [\n",
    "    # prioriteit_dummies\n",
    "    prioriteit,\n",
    "    oorz_code_enc,\n",
    "    geo_code_enc,\n",
    "    contractgb_enc,\n",
    "    techn_enc,\n",
    "    # techn_veld_dummies,\n",
    "    # oorz_groep_dummies\n",
    "]\n",
    "\n",
    "test_df = pd.concat([df_test['anm_tot_fh'], *features_to_use], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_pickle(\"data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier maken wij de json-files met de encoded values van de unieke waarden in de kolom, zodat dit beschikbaar is in het dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary van de dictionaries\n",
    "encodings = {'oorzaak_code': oorzc_dict,\n",
    " 'geo_code': geo_dict,\n",
    " 'contractgb': contrgb_dict,\n",
    " 'techn_veld': techn_dict\n",
    "}\n",
    "with open('data/feature_encodings.json', 'w') as outfile:\n",
    "    json.dump(encodings, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
